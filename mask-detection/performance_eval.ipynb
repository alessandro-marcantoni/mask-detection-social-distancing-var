{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask Detection - Performance Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications import mobilenet_v2 as mobilenet\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utilities import apply_boxes, average_precision, iou, get_video_frames, pad_input_image, recover_pad_output, extract_hog\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 562\n",
    "W = 1000\n",
    "TARGET_SIZE = (W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/mobilenet-model/mobilenet-mask-classification.h5\"\n",
    "svc_path = \"models/svm-model/svm-mask-classification.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load face detection model: SSD-MobileNetV2\n",
    "print(\"Load face detection model.\")\n",
    "model = load_model(\"models/retinaface-model\")\n",
    "print(\"Face detection model loaded.\")\n",
    "\n",
    "#Load mask classification model: MobilenetV2\n",
    "print(\"Load mask classification model.\")\n",
    "clf = load_model(model_path)\n",
    "print(\"Mask classification model loaded.\")\n",
    "\n",
    "#Load mask classification model: SVM\n",
    "print(\"Load mask classification model.\")\n",
    "with open(svc_path, 'rb') as file:\n",
    "    svc = pickle.load(file)\n",
    "print(\"Mask classification model loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame Extraction from Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract video frames\n",
    "print(\"Extracting frames.\")\n",
    "frames = get_video_frames(\"video/testset.mp4\", target_size = TARGET_SIZE)\n",
    "print(\"Frames: \", len(frames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "average_precisions = []\n",
    "true_positives = []\n",
    "false_negatives = []\n",
    "\n",
    "total_precision = []\n",
    "total_recalls = []\n",
    "\n",
    "classes = [0, 0, 0]\n",
    "mean_tps = [0, 0, 0]\n",
    "mean_ranks = [0, 0, 0]\n",
    "mean_precisions = [[], [], []]\n",
    "mean_recalls = [[], [], []]\n",
    "\n",
    "ssd_preds = []\n",
    "svm_preds = []\n",
    "\n",
    "labels = []\n",
    "times = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count classes\n",
    "print(\"Counting classes of test set\")\n",
    "for i in range(0, len(frames)):\n",
    "    for j in range(0,6):\n",
    "        with open(\"labels/\"+str(i)+\"-\"+str(j)+\".txt\", \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            label = int(lines[3])\n",
    "            classes[label] = classes[label] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = sum(classes)\n",
    "print(n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start inference on video frames\n",
    "show = False\n",
    "print(\"Start inference\")\n",
    "for i, frame in enumerate(frames):\n",
    "    #Start\n",
    "    start = time.time()\n",
    "    \n",
    "    #Preprocess frame\n",
    "    padded_frame, padding = pad_input_image(frame, 32)\n",
    "    \n",
    "    #Face inference\n",
    "    prediction = model(padded_frame[np.newaxis, ...]).numpy()\n",
    "    result = recover_pad_output(prediction, padding)\n",
    "\n",
    "    pred_bboxes = []\n",
    "    label_bboxes = []\n",
    "    label_classes = []\n",
    "\n",
    "    #Save bounding boxes\n",
    "    for bbox in result:\n",
    "        x1 = int(bbox[0] * W)\n",
    "        y1 = int(bbox[1] * H)\n",
    "        x2 = int(bbox[2] * W)\n",
    "        y2 = int(bbox[3] * H)\n",
    "        pred_bboxes.append((x1,y1, x2, y2))\n",
    "\n",
    "    for j in range(0,6):\n",
    "        with open(\"labels/\"+str(i)+\"-\"+str(j)+\".txt\", \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            p1 = [int(x) for x in lines[0].replace(\"[\", \"\").replace(\"]\", \"\").split(\" \")]\n",
    "            p2 = [int(x) for x in lines[1].replace(\"[\", \"\").replace(\"]\", \"\").split(\" \")]\n",
    "            x1, y1 = p1[0], p1[1]\n",
    "            x2, y2 = p2[0], p2[1]\n",
    "            label_bboxes.append((x1,y1, x2,y2))\n",
    "            label = int(lines[3])\n",
    "            labels.append(label)\n",
    "            label_classes.append(label)\n",
    "\n",
    "    #Mask classification inference\n",
    "    faces = [frame[bbox[1]:bbox[3], bbox[0]:bbox[2]] for bbox in label_bboxes]\n",
    "    resized_faces = np.array([cv.resize(f, (224, 224), interpolation=cv.INTER_CUBIC) for f in faces])\n",
    "\n",
    "    processed_faces = mobilenet.preprocess_input(resized_faces)\n",
    "    predictions = [np.argmax(r) for r in clf.predict(processed_faces)]\n",
    "\n",
    "    mrg = 5\n",
    "    svm_faces = [frame[(bbox[1]-mrg):(bbox[3]+mrg), (bbox[0]-mrg):(bbox[2]+mrg)] for bbox in label_bboxes]\n",
    "    svm_resized_faces = np.array([cv.resize(f, (128, 128), interpolation=cv.INTER_CUBIC) for f in svm_faces])\n",
    "    hog_faces = [extract_hog(cv.cvtColor(f, cv.COLOR_BGR2GRAY)) for f in svm_resized_faces]\n",
    "    svm_predictions = svc.predict(hog_faces)\n",
    "\n",
    "    if show:\n",
    "        show_faces = [frame[bbox[1]:bbox[3], bbox[0]:bbox[2]] for bbox in pred_bboxes]\n",
    "        show_resized_faces = np.array([cv.resize(f, (224, 224), interpolation=cv.INTER_CUBIC) for f in show_faces])\n",
    "        show_processed_faces = mobilenet.preprocess_input(show_resized_faces)\n",
    "        show_predictions = [np.argmax(r) for r in clf.predict(show_processed_faces)]\n",
    "    \n",
    "        boxed_frame = apply_boxes(frame, pred_bboxes, show_predictions, margin = 5)\n",
    "        _img = np.array(boxed_frame)\n",
    "        cv2.imshow(\"preview\", _img)\n",
    "\n",
    "    for prediction in predictions:\n",
    "        ssd_preds.append(prediction)\n",
    "\n",
    "    for prediction in svm_predictions:\n",
    "        svm_preds.append(prediction)\n",
    "    \n",
    "\n",
    "    #Find true positives\n",
    "    tps = []\n",
    "    fps = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for rank, pred_bbox in enumerate(pred_bboxes):\n",
    "        tp = False\n",
    "        for label_bbox in label_bboxes:\n",
    "            if iou(label_bbox, pred_bbox) > 0.1:\n",
    "                tp = True\n",
    "\n",
    "        if tp:\n",
    "            tps.append(tp)\n",
    "            true_positives.append(pred_bbox)\n",
    "            if predictions[rank] == label_classes[rank]:\n",
    "                mean_tps[label_classes[rank]] = mean_tps[label_classes[rank]] + 1\n",
    "        else:\n",
    "            fps.append(tp)\n",
    "            false_negatives.append(pred_bbox)\n",
    "\n",
    "        precision.append(len(tps)/(len(tps)+len(fps)))\n",
    "        recall.append(len(tps)/6)\n",
    "\n",
    "        total_precision.append(len(true_positives) / (len(true_positives) + len(false_negatives)))\n",
    "        total_recalls.append(len(true_positives) / n_labels)\n",
    "\n",
    "        mean_ranks[label_classes[rank]] = mean_ranks[label_classes[rank]] + 1\n",
    "        mean_precisions[label_classes[rank]].append( mean_tps[label_classes[rank]] / mean_ranks[label_classes[rank]] )\n",
    "        mean_recalls[label_classes[rank]].append( mean_tps[label_classes[rank]] / classes[label_classes[rank]] )\n",
    "\n",
    "    #Calculate average precision\n",
    "    ap = average_precision(precision, recall)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    average_precisions.append(ap)\n",
    "\n",
    "    #Finish\n",
    "    finish = time.time()\n",
    "    times.append(finish-start)\n",
    "    print(\"Elapsed \"+str(finish-start)+\" for frame \"+str(i))\n",
    "    key = cv.waitKey(20)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Medium average precision: \"+str(sum(average_precisions) / len(average_precisions)))\n",
    "print(\"RetinaFace Average Precision: \"+str(average_precision(total_precision, total_recalls)))\n",
    "print()\n",
    "\n",
    "rights = []\n",
    "for pred, label in zip(ssd_preds, labels):\n",
    "    if pred == label:\n",
    "        rights.append(pred)\n",
    "\n",
    "svm_rights = []\n",
    "for pred, label in zip(svm_preds, labels):\n",
    "    if pred == label:\n",
    "        svm_rights.append(pred)\n",
    "\n",
    "print(\"SSD Accuracy: \"+str(len(rights) / len(labels)))\n",
    "cm = confusion_matrix(labels, ssd_preds)\n",
    "print(\"SSD Confusion matrix:\\n\", cm)\n",
    "_, counts = np.unique(labels, return_counts=True)\n",
    "mca = np.mean(cm.diagonal() / counts)\n",
    "print(\"SSD Mean class accuracy: \"+str(mca))\n",
    "print()\n",
    "\n",
    "print(\"SVM Accuracy: \"+str(len(svm_rights) / len(labels)))\n",
    "svm_cm = confusion_matrix(labels, svm_preds)\n",
    "print(\"SVM Confusion matrix:\\n\", svm_cm)\n",
    "_, svm_counts = np.unique(labels, return_counts=True)\n",
    "svm_mca = np.mean(svm_cm.diagonal() / svm_counts)\n",
    "print(\"SVM Mean class accuracy: \"+str(svm_mca))\n",
    "print()\n",
    "\n",
    "ap0 = average_precision(mean_precisions[0], mean_recalls[0])\n",
    "ap1 = average_precision(mean_precisions[1], mean_recalls[1])\n",
    "ap2 = average_precision(mean_precisions[2], mean_recalls[2])\n",
    "\n",
    "print(\"Average Precision on class 0 (no mask): \"+str(ap0))\n",
    "print(\"Average Precision on class 1 (mask): \"+str(ap1))\n",
    "print(\"Average Precision on class 2 (incorrect mask): \"+str(ap2))\n",
    "print(\"Mean Average Precision: \"+str((ap0+ap1+ap2)/3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n",
    "\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, [\"no mask\", \"mask\", \"mask incorrect\"])\n",
    "plot_confusion_matrix(svm_cm, [\"no mask\", \"mask\", \"mask incorrect\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
