{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask Detection - Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from skimage import color\n",
    "from skimage.feature import hog\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    \"without_mask\": 0,\n",
    "    \"with_mask\": 1,\n",
    "    \"mask_worn_incorrect\": 2\n",
    "}\n",
    "\n",
    "one_hot_encoding = {\n",
    "    0: [1, 0, 0],\n",
    "    1: [0, 1, 0],\n",
    "    2: [0, 0, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, label, labels = classes):\n",
    "    paths = glob.glob(\"./\" + path + \"/\"  + label + \"/*\")\n",
    "    paths.sort()\n",
    "    return np.array([np.array(cv.imread(p)) for p in paths]), np.array([labels[label] for p in paths])\n",
    "\n",
    "def load_resized_dataset(path, label, labels = classes):\n",
    "    paths = glob.glob(\"./\" + path + \"/\"  + label + \"/*\")\n",
    "    paths.sort()\n",
    "    return np.array([cv.resize(cv.imread(p), (224, 224), interpolation=cv.INTER_CUBIC) for p in paths]), np.array([labels[label] for p in paths])\n",
    "\n",
    "def load_double_resized_dataset(path, label, labels = classes):\n",
    "    paths = glob.glob(\"./\" + path + \"/\" + label + \"/*\")\n",
    "    paths.sort()\n",
    "    return np.array([np.array(double_resize(cv.imread(p))) for p in paths]), [labels[label] for p in paths]\n",
    "\n",
    "def load_gray_dataset(label, labels = classes):\n",
    "    paths = glob.glob(\"./face-mask-dataset/\"  + label + \"/*\")\n",
    "    paths.sort()\n",
    "    return [np.array(cv.cvtColor(cv.imread(p), cv.COLOR_BGR2GRAY)) for p in paths], [labels[label] for p in paths]\n",
    "\n",
    "def load_images_rgb(path):\n",
    "    paths = glob.glob(path + \"/*\")\n",
    "    paths.sort()\n",
    "    return [np.array(cv.imread(p)) for p in paths]\n",
    "\n",
    "def load_images(path):\n",
    "    paths = glob.glob(path + \"/*\")\n",
    "    paths.sort()\n",
    "    return [np.array(cv.cvtColor(cv.imread(p), cv.COLOR_BGR2GRAY)) for p in paths]\n",
    "\n",
    "def extract_hog(image, ppc = 16):\n",
    "    features, _ = hog(image, orientations=8, pixels_per_cell=(ppc,ppc),cells_per_block=(4, 4),block_norm= 'L2',visualize=True)\n",
    "    return features\n",
    "\n",
    "def double_resize(image, first_size = (30, 30), target_size = (224, 224)):\n",
    "    resized = cv.resize(image, (first_size), interpolation = cv.INTER_CUBIC)\n",
    "    return cv.resize(resized, (target_size), interpolation = cv.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2994 2994\n",
      "2994 2994\n",
      "2994 2994\n",
      "17964 17964\n"
     ]
    }
   ],
   "source": [
    "mask, mask_labels = load_gray_dataset(\"with_mask\")\n",
    "no_mask, no_mask_labels = load_gray_dataset(\"without_mask\")\n",
    "mask_incorrect, mask_incorrect_labels = load_gray_dataset(\"mask_worn_incorrect\")\n",
    "\n",
    "print(len(mask), len(mask_labels))\n",
    "print(len(no_mask), len(no_mask_labels))\n",
    "print(len(mask_incorrect), len(mask_incorrect_labels))\n",
    "\n",
    "images = np.concatenate((mask, no_mask, mask_incorrect))\n",
    "labels = np.concatenate((mask_labels, no_mask_labels, mask_incorrect_labels))\n",
    "\n",
    "images = np.concatenate((images, [cv.flip(i, 1) for i in images]))\n",
    "labels = np.concatenate((labels, labels))\n",
    "\n",
    "print(len(images), len(labels))\n",
    "\n",
    "for i in images:\n",
    "    assert(i.shape == (128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_train = [extract_hog(image) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'degree': 3, 'gamma': 0.05, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "parameters = [{\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"kernel\": [\"poly\"],\n",
    "    \"degree\": [2, 3, 4, 5],\n",
    "    \"gamma\": [0.05, 0.025]\n",
    "}, {\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"kernel\": [\"rbf\"],\n",
    "    \"gamma\": [0.05, 0.025]\n",
    "}]\n",
    "n_folds = 3\n",
    "grid_search_cv = GridSearchCV(model, parameters, cv=n_folds)\n",
    "\n",
    "grid_search_cv.fit(hog_train, labels)\n",
    "print(grid_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.05, kernel='poly')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=10, degree=3, gamma=0.05, kernel=\"poly\")\n",
    "clf.fit(hog_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"svm-model2.pkl\"\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"svm-model.pkl\"\n",
    "with open(filename, 'rb') as file:\n",
    "    clf = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = load_images_rgb(\"faces\")\n",
    "resized_faces = [cv.resize(f, (128, 128), interpolation=cv.INTER_CUBIC) for f in faces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_faces = [extract_hog(f) for f in resized_faces]\n",
    "print(clf.score(hog_faces,  [1 for i in range(len(faces))]))\n",
    "results = clf.predict(hog_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 0), (15, 0), (18, 0), (21, 2), (25, 0), (28, 0), (48, 0), (51, 0), (124, 0), (127, 0), (131, 0)]\n"
     ]
    }
   ],
   "source": [
    "print([e for e in zip([i for i, c in enumerate(results) if c != 1],\n",
    "    [c for c in results if c != 1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSD-MobilenetV2 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:21:31.197310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 14:21:31.217670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 14:21:31.218180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 14:21:31.224276: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-29 14:21:31.224720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 14:21:31.225261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 14:21:31.225659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 14:21:31.722778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 14:21:31.723316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 14:21:31.723714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-29 14:21:31.724108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9650 MB memory:  -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:00:10.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.3),\n",
    "        layers.RandomZoom(0.2)\n",
    "    ]\n",
    ")\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "augmentation = data_augmentation(inputs)\n",
    "mobilenet = tf.keras.applications.mobilenet_v2.MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=input_shape)(augmentation)\n",
    "maxpool = tf.keras.layers.GlobalMaxPooling2D()(mobilenet)\n",
    "output = tf.keras.layers.Dense(3, activation='softmax')(maxpool)\n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "for layer in model.layers[:-23]:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_resized = True\n",
    "\n",
    "mask, mask_labels = load_double_resized_dataset(\"face-mask-dataset\", \"with_mask\") if double_resized else load_resized_dataset(\"face-mask-dataset\", \"with_mask\")\n",
    "no_mask, no_mask_labels = load_double_resized_dataset(\"face-mask-dataset\", \"without_mask\") if double_resized else load_resized_dataset(\"face-mask-dataset\", \"without_mask\")\n",
    "mask_incorrect, mask_incorrect_labels = load_double_resized_dataset(\"face-mask-dataset\", \"mask_worn_incorrect\") if double_resized else load_resized_dataset(\"face-mask-dataset\", \"mask_worn_incorrect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2994 2994\n",
      "2994 2994\n",
      "2994 2994\n",
      "8982 8982\n"
     ]
    }
   ],
   "source": [
    "print(len(mask), len(mask_labels))\n",
    "print(len(no_mask), len(no_mask_labels))\n",
    "print(len(mask_incorrect), len(mask_incorrect_labels))\n",
    "\n",
    "images = np.concatenate((mask, no_mask, mask_incorrect))\n",
    "labels = np.concatenate((mask_labels, no_mask_labels, mask_incorrect_labels))\n",
    "labels = np.array([one_hot_encoding[i] for i in labels])\n",
    "\n",
    "images = tf.keras.applications.mobilenet_v2.preprocess_input(images)\n",
    "print(len(images), len(labels))\n",
    "for i in images:\n",
    "    assert(i.shape == (224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = False\n",
    "\n",
    "if split:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(images, labels, train_size=0.8, shuffle=True, random_state=0)\n",
    "else:\n",
    "    x_train = images\n",
    "    y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.0001\n",
    "    if epoch < 15:\n",
    "        return 0.00005\n",
    "    return 0.00001\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.LearningRateScheduler(schedule=lr_schedule),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='mobilenet_epoch-{epoch:02d}_loss-{loss:.4f}_val_loss-{val_loss:.4f}.h5'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:21:55.649470: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4326174720 exceeds 10% of free system memory.\n",
      "2022-03-29 14:21:57.377475: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4326174720 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:22:02.643298: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 37s 138ms/step - loss: 0.7403 - accuracy: 0.8168 - val_loss: 0.2477 - val_accuracy: 0.9082 - lr: 1.0000e-04\n",
      "Epoch 2/200\n",
      "225/225 [==============================] - 29s 130ms/step - loss: 0.3256 - accuracy: 0.9065 - val_loss: 0.1373 - val_accuracy: 0.9449 - lr: 1.0000e-04\n",
      "Epoch 3/200\n",
      "225/225 [==============================] - 29s 131ms/step - loss: 0.2552 - accuracy: 0.9297 - val_loss: 0.1146 - val_accuracy: 0.9588 - lr: 1.0000e-04\n",
      "Epoch 4/200\n",
      "225/225 [==============================] - 30s 131ms/step - loss: 0.2149 - accuracy: 0.9396 - val_loss: 0.0481 - val_accuracy: 0.9816 - lr: 1.0000e-04\n",
      "Epoch 5/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.1662 - accuracy: 0.9549 - val_loss: 0.4384 - val_accuracy: 0.8436 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.1325 - accuracy: 0.9609 - val_loss: 0.1459 - val_accuracy: 0.9471 - lr: 5.0000e-05\n",
      "Epoch 7/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.1084 - accuracy: 0.9695 - val_loss: 0.1283 - val_accuracy: 0.9460 - lr: 5.0000e-05\n",
      "Epoch 8/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0920 - accuracy: 0.9715 - val_loss: 0.0099 - val_accuracy: 0.9961 - lr: 5.0000e-05\n",
      "Epoch 9/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0923 - accuracy: 0.9713 - val_loss: 0.0120 - val_accuracy: 0.9939 - lr: 5.0000e-05\n",
      "Epoch 10/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0736 - accuracy: 0.9777 - val_loss: 0.0553 - val_accuracy: 0.9811 - lr: 5.0000e-05\n",
      "Epoch 11/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0781 - accuracy: 0.9752 - val_loss: 0.0200 - val_accuracy: 0.9928 - lr: 5.0000e-05\n",
      "Epoch 12/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0705 - accuracy: 0.9776 - val_loss: 0.0631 - val_accuracy: 0.9761 - lr: 5.0000e-05\n",
      "Epoch 13/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0513 - accuracy: 0.9840 - val_loss: 0.0240 - val_accuracy: 0.9917 - lr: 5.0000e-05\n",
      "Epoch 14/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0516 - accuracy: 0.9841 - val_loss: 0.0071 - val_accuracy: 0.9983 - lr: 5.0000e-05\n",
      "Epoch 15/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0614 - accuracy: 0.9809 - val_loss: 0.0162 - val_accuracy: 0.9950 - lr: 5.0000e-05\n",
      "Epoch 16/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0418 - accuracy: 0.9873 - val_loss: 0.0105 - val_accuracy: 0.9961 - lr: 1.0000e-05\n",
      "Epoch 17/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0345 - accuracy: 0.9884 - val_loss: 0.0052 - val_accuracy: 0.9978 - lr: 1.0000e-05\n",
      "Epoch 18/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0386 - accuracy: 0.9858 - val_loss: 0.0060 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 19/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0328 - accuracy: 0.9887 - val_loss: 0.0036 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 20/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0311 - accuracy: 0.9889 - val_loss: 0.0022 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 21/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0288 - accuracy: 0.9889 - val_loss: 0.0040 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 22/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0301 - accuracy: 0.9903 - val_loss: 0.0079 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 23/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0247 - accuracy: 0.9907 - val_loss: 0.0086 - val_accuracy: 0.9978 - lr: 1.0000e-05\n",
      "Epoch 24/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0303 - accuracy: 0.9896 - val_loss: 0.0210 - val_accuracy: 0.9928 - lr: 1.0000e-05\n",
      "Epoch 25/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0295 - accuracy: 0.9911 - val_loss: 0.0146 - val_accuracy: 0.9961 - lr: 1.0000e-05\n",
      "Epoch 26/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0271 - accuracy: 0.9903 - val_loss: 0.0148 - val_accuracy: 0.9955 - lr: 1.0000e-05\n",
      "Epoch 27/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0209 - accuracy: 0.9928 - val_loss: 0.0082 - val_accuracy: 0.9972 - lr: 1.0000e-05\n",
      "Epoch 28/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0261 - accuracy: 0.9907 - val_loss: 0.0123 - val_accuracy: 0.9972 - lr: 1.0000e-05\n",
      "Epoch 29/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 0.0138 - val_accuracy: 0.9955 - lr: 1.0000e-05\n",
      "Epoch 30/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.0078 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 31/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0224 - accuracy: 0.9908 - val_loss: 0.0061 - val_accuracy: 0.9978 - lr: 1.0000e-05\n",
      "Epoch 32/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.0024 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 33/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0231 - accuracy: 0.9911 - val_loss: 0.0029 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 34/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.0047 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 35/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0186 - accuracy: 0.9936 - val_loss: 0.0043 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 36/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 0.0033 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 37/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0181 - accuracy: 0.9933 - val_loss: 0.0044 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 38/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 0.0055 - val_accuracy: 0.9978 - lr: 1.0000e-05\n",
      "Epoch 39/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.0049 - val_accuracy: 0.9978 - lr: 1.0000e-05\n",
      "Epoch 40/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.0065 - val_accuracy: 0.9978 - lr: 1.0000e-05\n",
      "Epoch 41/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 0.0068 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 42/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.0034 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 43/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 0.0038 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 44/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0116 - accuracy: 0.9954 - val_loss: 0.0084 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 45/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.0058 - val_accuracy: 0.9978 - lr: 1.0000e-05\n",
      "Epoch 46/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.0047 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 47/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.0016 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 48/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0028 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 49/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0019 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 50/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0024 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 51/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0036 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 52/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0126 - accuracy: 0.9955 - val_loss: 0.0042 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 53/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0101 - accuracy: 0.9961 - val_loss: 0.0021 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 54/200\n",
      "225/225 [==============================] - 30s 131ms/step - loss: 0.0111 - accuracy: 0.9954 - val_loss: 0.0026 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 55/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.0019 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 56/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0032 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 57/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.0054 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 58/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0106 - accuracy: 0.9957 - val_loss: 0.0065 - val_accuracy: 0.9978 - lr: 1.0000e-05\n",
      "Epoch 59/200\n",
      "225/225 [==============================] - 30s 131ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.0093 - val_accuracy: 0.9967 - lr: 1.0000e-05\n",
      "Epoch 60/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.0144 - val_accuracy: 0.9961 - lr: 1.0000e-05\n",
      "Epoch 61/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.0051 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 62/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0097 - accuracy: 0.9960 - val_loss: 0.0057 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 63/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.0133 - val_accuracy: 0.9933 - lr: 1.0000e-05\n",
      "Epoch 64/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0104 - accuracy: 0.9961 - val_loss: 0.0030 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 65/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.0067 - val_accuracy: 0.9967 - lr: 1.0000e-05\n",
      "Epoch 66/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0039 - val_accuracy: 0.9978 - lr: 1.0000e-05\n",
      "Epoch 67/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0048 - val_accuracy: 0.9978 - lr: 1.0000e-05\n",
      "Epoch 68/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0062 - accuracy: 0.9972 - val_loss: 0.0063 - val_accuracy: 0.9972 - lr: 1.0000e-05\n",
      "Epoch 69/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.0092 - val_accuracy: 0.9955 - lr: 1.0000e-05\n",
      "Epoch 70/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.0039 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 71/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0039 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 72/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0035 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 73/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0121 - val_accuracy: 0.9939 - lr: 1.0000e-05\n",
      "Epoch 74/200\n",
      "225/225 [==============================] - 30s 131ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0113 - val_accuracy: 0.9955 - lr: 1.0000e-05\n",
      "Epoch 75/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0066 - accuracy: 0.9972 - val_loss: 0.0069 - val_accuracy: 0.9967 - lr: 1.0000e-05\n",
      "Epoch 76/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0102 - accuracy: 0.9961 - val_loss: 0.0081 - val_accuracy: 0.9961 - lr: 1.0000e-05\n",
      "Epoch 77/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.0049 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 78/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.0061 - val_accuracy: 0.9972 - lr: 1.0000e-05\n",
      "Epoch 79/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0057 - val_accuracy: 0.9978 - lr: 1.0000e-05\n",
      "Epoch 80/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0069 - val_accuracy: 0.9972 - lr: 1.0000e-05\n",
      "Epoch 81/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0090 - accuracy: 0.9962 - val_loss: 0.0088 - val_accuracy: 0.9967 - lr: 1.0000e-05\n",
      "Epoch 82/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0046 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 83/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0037 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 84/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0027 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 85/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0030 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 86/200\n",
      "225/225 [==============================] - 30s 134ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0030 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 87/200\n",
      "225/225 [==============================] - 30s 134ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.0037 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 88/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0185 - val_accuracy: 0.9944 - lr: 1.0000e-05\n",
      "Epoch 89/200\n",
      "225/225 [==============================] - 30s 135ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.0058 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 90/200\n",
      "225/225 [==============================] - 30s 134ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.0041 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 91/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.0057 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 92/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0071 - accuracy: 0.9972 - val_loss: 0.0051 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 93/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0055 - accuracy: 0.9978 - val_loss: 0.0106 - val_accuracy: 0.9961 - lr: 1.0000e-05\n",
      "Epoch 94/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0052 - accuracy: 0.9978 - val_loss: 0.0042 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 95/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0143 - val_accuracy: 0.9967 - lr: 1.0000e-05\n",
      "Epoch 96/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0074 - val_accuracy: 0.9978 - lr: 1.0000e-05\n",
      "Epoch 97/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.0018 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 98/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.0027 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 99/200\n",
      "225/225 [==============================] - 30s 131ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.0032 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 100/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.0020 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 101/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0064 - accuracy: 0.9972 - val_loss: 0.0026 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 102/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0031 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 103/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.0016 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 104/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0051 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 105/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.0026 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 106/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.0011 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 107/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 0.0023 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 108/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0012 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 109/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0038 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 110/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 111/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0075 - val_accuracy: 0.9967 - lr: 1.0000e-05\n",
      "Epoch 112/200\n",
      "225/225 [==============================] - 30s 131ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.0095 - val_accuracy: 0.9967 - lr: 1.0000e-05\n",
      "Epoch 113/200\n",
      "225/225 [==============================] - 30s 131ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0038 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 114/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 0.0025 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 115/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.0065 - val_accuracy: 0.9972 - lr: 1.0000e-05\n",
      "Epoch 116/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0082 - val_accuracy: 0.9961 - lr: 1.0000e-05\n",
      "Epoch 117/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0121 - val_accuracy: 0.9950 - lr: 1.0000e-05\n",
      "Epoch 118/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0042 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 119/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0076 - val_accuracy: 0.9978 - lr: 1.0000e-05\n",
      "Epoch 120/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0016 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 121/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0063 - accuracy: 0.9975 - val_loss: 0.0042 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 122/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0060 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 123/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0077 - val_accuracy: 0.9978 - lr: 1.0000e-05\n",
      "Epoch 124/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.0042 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 125/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 126/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 127/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.0032 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 128/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0036 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 129/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0046 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 130/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0033 - val_accuracy: 0.9989 - lr: 1.0000e-05\n",
      "Epoch 131/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0061 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 132/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0077 - val_accuracy: 0.9972 - lr: 1.0000e-05\n",
      "Epoch 133/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0120 - val_accuracy: 0.9955 - lr: 1.0000e-05\n",
      "Epoch 134/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0013 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 135/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.0043 - val_accuracy: 0.9978 - lr: 1.0000e-05\n",
      "Epoch 136/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 5.6057e-04 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 137/200\n",
      "225/225 [==============================] - 30s 132ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0014 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 138/200\n",
      "225/225 [==============================] - 29s 131ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0010 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 139/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0014 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 140/200\n",
      "225/225 [==============================] - 30s 133ms/step - loss: 0.0032 - accuracy: 0.9985 - val_loss: 0.0020 - val_accuracy: 0.9994 - lr: 1.0000e-05\n",
      "Epoch 141/200\n",
      "111/225 [=============>................] - ETA: 14s - loss: 0.0019 - accuracy: 0.9994"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=x_train,\n",
    "            y=y_train,\n",
    "            validation_split=0.2,\n",
    "            epochs=200,\n",
    "            shuffle=True,\n",
    "            callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5279c018c9ba5aaf89da8981ee94ffae841cf08408c6e7c2bf17280898d289c5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
